{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to end solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/go-eulhyeon/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/go-eulhyeon/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f097030653aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_evaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCVBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/go-eulhyeon/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/go-eulhyeon/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "MJTCP = 32292 #Michael Jordan total career points\n",
    "def assign_rnd_integer(dataset, number_of_times = 5, seed = MJTCP):\n",
    "    new_dataset = pd.DataFrame()\n",
    "    np.random.seed(seed)\n",
    "    for c in dataset.columns:\n",
    "        for i in range(number_of_times):\n",
    "            col_name = c+\"_\"+str(i)\n",
    "            unique_vals = dataset[c].unique()\n",
    "            labels = np.array(list(range(len(unique_vals))))\n",
    "            np.random.shuffle(labels)\n",
    "            mapping = pd.DataFrame({c: unique_vals, col_name: labels})\n",
    "            new_dataset[col_name] = (dataset[[c]]\n",
    "                                     .merge(mapping, on = c, how = 'left')[col_name]\n",
    "                                    ).values\n",
    "    return new_dataset\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "def extract_col_interaction(dataset, col1, col2, tfidf = True):\n",
    "    data = dataset.groupby([col1])[col2].agg(lambda x: \" \".join(list([str(y) for y in x])))\n",
    "    if tfidf:\n",
    "        vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"))\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(tokenizer=lambda x: x.split(\" \"))\n",
    "    \n",
    "    data_X = vectorizer.fit_transform(data)\n",
    "    dim_red = TruncatedSVD(n_components=1, random_state = 5511)\n",
    "    data_X = dim_red.fit_transform(data_X)\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    result[col1] = data.index.values\n",
    "    result[col1+\"_{}_svd\".format(col2)] = data_X.ravel()\n",
    "    return result\n",
    "\n",
    "import itertools\n",
    "def get_col_interactions_svd(dataset, tfidf = True):\n",
    "    new_dataset = pd.DataFrame()\n",
    "    for col1,col2 in itertools.permutations(dataset.columns, 2):\n",
    "        data = extract_col_interaction(dataset, col1,col2, tfidf)\n",
    "        col_name = [x for x in data.columns if \"svd\" in x][0]\n",
    "        new_dataset[col_name] = (dataset[[col1]]\n",
    "                                 .merge(data, on = col1, how = 'left')\n",
    "                                )[col_name]\n",
    "    return new_dataset\n",
    "\n",
    "def get_freq_encoding(dataset):\n",
    "    new_dataset = pd.DataFrame()\n",
    "    for c in dataset.columns:\n",
    "        data = dataset.groupby([c]).size().reset_index()\n",
    "        new_dataset[c+\"_freq\"] = dataset[[c]].merge(data, on = c, how = \"left\")[0]\n",
    "    return new_dataset\n",
    "\n",
    "def transform_dataset(train, test, func, func_params = {}):\n",
    "    dataset = pd.concat([train, test], ignore_index = True)\n",
    "    dataset = func(dataset, **func_params)\n",
    "    if isinstance(dataset, pd.DataFrame):\n",
    "        new_train = dataset.iloc[:train.shape[0],:].reset_index(drop = True)\n",
    "        new_test =  dataset.iloc[train.shape[0]:,:].reset_index(drop = True)\n",
    "    else:\n",
    "        new_train = dataset[:train.shape[0]]\n",
    "        new_test =  dataset[train.shape[0]:]\n",
    "    return new_train, new_test\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "def get_model(params, random_state = 42):\n",
    "    return lgbm.LGBMClassifier(\n",
    "        n_estimators=250,\n",
    "        metric='auc',\n",
    "        objective='binary', \n",
    "        n_jobs=3,\n",
    "        random_state = random_state,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "class TargetEncoding():\n",
    "    def __init__(self, columns_names ):\n",
    "        self.columns_names = columns_names\n",
    "        self.learned_values = {}\n",
    "        self.dataset_mean = np.nan\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        X_ = X.copy()\n",
    "        self.learned_values = {}\n",
    "        X_[\"__target__\"] = y\n",
    "        for c in [x for x in X_.columns if x in self.columns_names]:\n",
    "            self.learned_values[c] = (X_[[c,\"__target__\"]]\n",
    "                                      .groupby(c)[\"__target__\"].mean()\n",
    "                                      .reset_index())\n",
    "\n",
    "        self.dataset_mean = np.mean(y)\n",
    "        return self\n",
    "    def transform(self, X, **fit_params):\n",
    "        transformed_X = X[self.columns_names].copy()\n",
    "        for c in transformed_X.columns:\n",
    "            transformed_X[c] = (transformed_X[[c]]\n",
    "                                .merge(self.learned_values[c], on = c, how = 'left')\n",
    "                               )[\"__target__\"]\n",
    "        transformed_X = transformed_X.fillna(self.dataset_mean)\n",
    "        return transformed_X\n",
    "    def fit_transform(self, X, y, **fit_params):\n",
    "        self.fit(X,y)\n",
    "        return self.transform(X)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "def get_CV_target_encoding(data, y, encoder, cv = 5):\n",
    "    skfTE = StratifiedKFold(n_splits=cv, random_state = 545167, shuffle = True)\n",
    "    result = []\n",
    "    for train_indexTE, test_indexTE in skfTE.split(data, y):\n",
    "        encoder.fit(data.iloc[train_indexTE,:].reset_index(drop = True), y[train_indexTE])\n",
    "        tmp =  encoder.transform(data.iloc[test_indexTE,:].reset_index(drop = True))\n",
    "        tmp[\"index\"] = test_indexTE\n",
    "        result.append(tmp)\n",
    "    result = pd.concat(result, ignore_index = True)\n",
    "    result = result.sort_values('index').reset_index(drop = True).drop('index', axis = 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data directly from CatBoost\n",
    "from catboost.datasets import amazon\n",
    "train, test = amazon()\n",
    "\n",
    "target = \"ACTION\"\n",
    "col4train = [x for x in train.columns if x not in [target, \"ROLE_TITLE\"]]\n",
    "y = train[target].values\n",
    "\n",
    "train[col4train] = train[col4train].values.astype(str)\n",
    "test[col4train] = test[col4train].values.astype(str)\n",
    "\n",
    "from itertools import combinations\n",
    "new_col4train = col4train\n",
    "for c1,c2 in combinations(col4train, 2):\n",
    "    name = \"{}_{}\".format(c1,c2)\n",
    "    new_col4train.append(name)\n",
    "    train[name] = train[c1] + \"_\" + train[c2]\n",
    "    test[name] = test[c1] + \"_\" + test[c2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset #1\n",
    "cols_svd = ['MGR_ID_ROLE_CODE','MGR_ID_ROLE_DEPTNAME','MGR_ID_ROLE_FAMILY', \n",
    "            'RESOURCE_MGR_ID','RESOURCE_ROLE_CODE', 'RESOURCE_ROLE_FAMILY',\n",
    "            'RESOURCE_ROLE_ROLLUP_1','RESOURCE_ROLE_ROLLUP_2','RESOURCE',\n",
    "            'ROLE_DEPTNAME_ROLE_CODE','ROLE_DEPTNAME_ROLE_FAMILY',\n",
    "            'ROLE_FAMILY_DESC_ROLE_FAMILY','ROLE_FAMILY_ROLE_CODE',\n",
    "            'ROLE_FAMILY','ROLE_ROLLUP_1_ROLE_DEPTNAME',\n",
    "            'ROLE_ROLLUP_1_ROLE_FAMILY_DESC', 'ROLE_ROLLUP_1_ROLE_FAMILY',\n",
    "            'ROLE_ROLLUP_1','ROLE_ROLLUP_2']\n",
    "\n",
    "cols_rnd = ['MGR_ID_ROLE_DEPTNAME','MGR_ID_ROLE_FAMILY','MGR_ID_ROLE_ROLLUP_1',\n",
    " 'MGR_ID_ROLE_ROLLUP_2','MGR_ID','RESOURCE_MGR_ID','RESOURCE_ROLE_CODE',\n",
    " 'RESOURCE_ROLE_FAMILY_DESC','RESOURCE_ROLE_FAMILY','RESOURCE_ROLE_ROLLUP_1',\n",
    " 'RESOURCE_ROLE_ROLLUP_2','ROLE_DEPTNAME_ROLE_FAMILY_DESC','ROLE_FAMILY_DESC_ROLE_CODE',\n",
    " 'ROLE_FAMILY_DESC_ROLE_FAMILY','ROLE_FAMILY','ROLE_ROLLUP_1_ROLE_CODE',\n",
    " 'ROLE_ROLLUP_1_ROLE_DEPTNAME','ROLE_ROLLUP_1_ROLE_FAMILY_DESC','ROLE_ROLLUP_2_ROLE_FAMILY']\n",
    "\n",
    "cols_freq = ['MGR_ID_ROLE_DEPTNAME','RESOURCE_MGR_ID','RESOURCE_ROLE_CODE',\n",
    " 'RESOURCE_ROLE_DEPTNAME','RESOURCE_ROLE_FAMILY_DESC','RESOURCE_ROLE_FAMILY',\n",
    " 'RESOURCE_ROLE_ROLLUP_1','ROLE_DEPTNAME_ROLE_FAMILY_DESC','ROLE_DEPTNAME_ROLE_FAMILY',\n",
    " 'ROLE_DEPTNAME','ROLE_FAMILY_DESC_ROLE_CODE','ROLE_FAMILY_DESC_ROLE_FAMILY',\n",
    " 'ROLE_ROLLUP_1_ROLE_CODE','ROLE_ROLLUP_2_ROLE_DEPTNAME']\n",
    "\n",
    "data_svd = transform_dataset(train[cols_svd], test[cols_svd], get_col_interactions_svd)\n",
    "data_rnd = transform_dataset(train[cols_rnd], test[cols_rnd], \n",
    "                             assign_rnd_integer, {\"number_of_times\":5})\n",
    "data_freq = transform_dataset(train[cols_freq], test[cols_freq], get_freq_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([x[0] for x in [data_svd, data_rnd, data_freq]], axis = 1)\n",
    "data_test = pd.concat([x[1] for x in [data_svd, data_rnd, data_freq]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape, Train: {}, Test: {}\".format(data_train.shape, data_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del([data_svd, data_rnd, data_freq])\n",
    "gc.collect()\n",
    "data_train = data_train.values\n",
    "data_test = data_test.values\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 0.312002398119274,\n",
    " 'lambda_l1': 1.919962415701389,\n",
    " 'learning_rate': 0.03363113877976891,\n",
    " 'max_bin': 484,\n",
    " 'max_depth': 10,\n",
    " 'min_child_weight': 0.035307873174480586,\n",
    " 'num_leaves': 220}\n",
    "\n",
    "seeds = [42,146,78,6257,8373,737,5425,154,6262]\n",
    "\n",
    "predictions_1 = []\n",
    "for s in seeds:\n",
    "    model = get_model(params, random_state = s)\n",
    "    model.fit(data_train, y)\n",
    "    predictions_1.append(model.predict_proba(data_test)[:,1].ravel())\n",
    "predictions_1 = np.stack(predictions_1, -1).mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del([data_train, data_test, model])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset #2\n",
    "cols_svd = ['MGR_ID','RESOURCE_MGR_ID','RESOURCE_ROLE_CODE',\n",
    " 'RESOURCE_ROLE_DEPTNAME','RESOURCE_ROLE_FAMILY_DESC','RESOURCE_ROLE_FAMILY',\n",
    " 'RESOURCE_ROLE_ROLLUP_1','RESOURCE','ROLE_CODE',\n",
    " 'ROLE_DEPTNAME_ROLE_CODE','ROLE_DEPTNAME_ROLE_FAMILY','ROLE_FAMILY_DESC_ROLE_CODE',\n",
    " 'ROLE_FAMILY_DESC_ROLE_FAMILY','ROLE_FAMILY_DESC','ROLE_ROLLUP_1_ROLE_DEPTNAME',\n",
    " 'ROLE_ROLLUP_1_ROLE_FAMILY','ROLE_ROLLUP_1_ROLE_ROLLUP_2','ROLE_ROLLUP_2_ROLE_FAMILY_DESC',\n",
    " 'ROLE_ROLLUP_2_ROLE_FAMILY','ROLE_ROLLUP_2']\n",
    "\n",
    "cols_rnd = ['MGR_ID_ROLE_CODE','MGR_ID_ROLE_DEPTNAME','MGR_ID_ROLE_FAMILY_DESC',\n",
    " 'MGR_ID_ROLE_ROLLUP_1','MGR_ID','RESOURCE_ROLE_DEPTNAME',\n",
    " 'RESOURCE_ROLE_FAMILY','RESOURCE_ROLE_ROLLUP_1','ROLE_CODE',\n",
    " 'ROLE_DEPTNAME_ROLE_FAMILY_DESC','ROLE_FAMILY_DESC_ROLE_CODE',\n",
    " 'ROLE_FAMILY_DESC_ROLE_FAMILY','ROLE_FAMILY_ROLE_CODE',\n",
    " 'ROLE_ROLLUP_1_ROLE_CODE','ROLE_ROLLUP_1_ROLE_FAMILY_DESC',\n",
    " 'ROLE_ROLLUP_1_ROLE_ROLLUP_2']\n",
    "\n",
    "cols_freq = ['MGR_ID_ROLE_CODE','MGR_ID_ROLE_DEPTNAME','MGR_ID_ROLE_ROLLUP_1',\n",
    " 'MGR_ID_ROLE_ROLLUP_2','MGR_ID','RESOURCE_MGR_ID',\n",
    " 'RESOURCE_ROLE_DEPTNAME','RESOURCE_ROLE_FAMILY_DESC','RESOURCE_ROLE_ROLLUP_2',\n",
    " 'RESOURCE','ROLE_DEPTNAME_ROLE_FAMILY_DESC','ROLE_DEPTNAME',\n",
    " 'ROLE_FAMILY_DESC','ROLE_FAMILY','ROLE_ROLLUP_1_ROLE_FAMILY_DESC',\n",
    " 'ROLE_ROLLUP_1_ROLE_FAMILY','ROLE_ROLLUP_1_ROLE_ROLLUP_2',\n",
    " 'ROLE_ROLLUP_1','ROLE_ROLLUP_2_ROLE_CODE','ROLE_ROLLUP_2']\n",
    "\n",
    "cols_te = ['MGR_ID','RESOURCE_MGR_ID','RESOURCE_ROLE_CODE',\n",
    " 'RESOURCE_ROLE_DEPTNAME','RESOURCE_ROLE_ROLLUP_2','RESOURCE',\n",
    " 'ROLE_CODE','ROLE_DEPTNAME_ROLE_FAMILY_DESC','ROLE_DEPTNAME_ROLE_FAMILY',\n",
    " 'ROLE_FAMILY_DESC_ROLE_CODE','ROLE_FAMILY_DESC','ROLE_FAMILY_ROLE_CODE',\n",
    " 'ROLE_ROLLUP_1_ROLE_FAMILY','ROLE_ROLLUP_2_ROLE_FAMILY','ROLE_ROLLUP_2']\n",
    "\n",
    "data_svd = transform_dataset(train[cols_svd], test[cols_svd], get_col_interactions_svd)\n",
    "data_rnd = transform_dataset(train[cols_rnd], test[cols_rnd], \n",
    "                             assign_rnd_integer, {\"number_of_times\":5})\n",
    "data_freq = transform_dataset(train[cols_freq], test[cols_freq], get_freq_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TargetEncoding(columns_names = cols_te)\n",
    "data_te_tr = get_CV_target_encoding(train[cols_te], y, te, 5)\n",
    "te.fit(train[cols_te], y)\n",
    "data_te_te = te.transform(test[cols_te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([x[0] for x in [data_svd, data_rnd, data_freq]], axis = 1)\n",
    "data_test = pd.concat([x[1] for x in [data_svd, data_rnd, data_freq]], axis = 1)\n",
    "data_train = pd.concat([data_train, data_te_tr], axis = 1)\n",
    "data_test = pd.concat([data_test, data_te_te], axis = 1)\n",
    "print(\"Dataset shape, Train: {}, Test: {}\".format(data_train.shape, data_test.shape))\n",
    "del([data_svd, data_rnd, data_freq, data_te_tr, data_te_te])\n",
    "gc.collect()\n",
    "data_train = data_train.values\n",
    "data_test = data_test.values\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 0.5280533549534434,\n",
    " 'lambda_l1': 0.1267270702844549,\n",
    " 'learning_rate': 0.012220447574715732,\n",
    " 'max_bin': 131,\n",
    " 'max_depth': 18,\n",
    " 'min_child_weight': 1.1518716916679328,\n",
    " 'num_leaves': 184}\n",
    "\n",
    "predictions_2 = []\n",
    "for s in seeds:\n",
    "    model = get_model(params, random_state = s)\n",
    "    model.fit(data_train, y)\n",
    "    predictions_2.append(model.predict_proba(data_test)[:,1].ravel())\n",
    "predictions_2 = np.stack(predictions_2, -1).mean(-1)\n",
    "\n",
    "del([data_train, data_test, model])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"Id\"] = test[\"id\"]\n",
    "submission[\"ACTION\"] = (predictions_1 + predictions_2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
